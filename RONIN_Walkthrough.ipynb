{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RONIN Walkthrough \n",
    "___\n",
    "\n",
    "This notebook contains a brief introduction to training and evaluating a random forest radar quality control algorithm using Julia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/Grad_School/Research/Ronin`\n"
     ]
    }
   ],
   "source": [
    "##Begin by loading dependencies \n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate() \n",
    "##Make sure Julia can see our module \n",
    "push!(LOAD_PATH, \"./src/\")\n",
    "\n",
    "###Load key functionality \n",
    "###This will take a while the first time you do it \n",
    "using Ronin "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Splitting data into training and testing sets\n",
    "___\n",
    "We'll begin by partitioning our data into scans that will be used for training the model and scans that will be used in its evaluation. It's important to keep these separate. \n",
    "<h2><span style=\"color:Red\">WARNING: This function will begin by DELETING the training and testing directories to clean them</span></h2>\n",
    "It then softlinks the divded files to their respective directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/ischluesche/Documents/Grad_School/Research/Ronin/CFRADIALS/CASES/TESTING\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Make sure to use absolute paths here \n",
    "##These are EXAMPLES, make sure to edit for your own directory setup\n",
    "CASE_PATHS= [\"/Users/ischluesche/Documents/Grad_School/Research/Ronin/CFRADIALS/CASES/BAMEX\", \n",
    "             \"/Users/ischluesche/Documents/Grad_School/Research/Ronin/CFRADIALS/CASES/HAGUPIT\", \n",
    "             \"/Users/ischluesche/Documents/Grad_School/Research/Ronin/CFRADIALS/CASES/RITA\", \n",
    "             \"/Users/ischluesche/Documents/Grad_School/Research/Ronin/CFRADIALS/CASES/VORTEX\"]\n",
    "\n",
    "TRAINING_PATH = \"/Users/ischluesche/Documents/Grad_School/Research/Ronin/CFRADIALS/CASES/TRAINING\"\n",
    "TESTING_PATH = \"/Users/ischluesche/Documents/Grad_School/Research/Ronin/CFRADIALS/CASES/TESTING\"\n",
    "\n",
    "split_training_testing!(CASE_PATHS, TRAINING_PATH, TESTING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING/\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_PATH = \"/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING/\"\n",
    "TESTING_PATH = \"/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Configure model\n",
    "___\n",
    "We'll now set up a configuartion object for use in our model. This structure contains \n",
    "key information and settings such as the number of models to use, the decision thresholds for each model, and locations to output data to. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, the first step in the process is calculating a set of input features containing information about each gate in the training radar sweeps.\n",
    "`task_paths` specifies the location of the file containing the information about what features the user wishes to calculate. It should be the same length as the number of models in the chain (more below). \n",
    "`input_path` is the path to the file \n",
    "or directory where the sweeps are located. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING/\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_paths = [\"./NOAA_all_params.txt\", \"./NOAA_all_params.txt\"]\n",
    "input_path = TRAINING_PATH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ronin can also create a \"multi-pass\" model, where a model is trained on the full dataset, and successive models are trained on subsets of these data. The motivation for this setup is to leverage the probablistic information provided by the random forest approach. Consider a gate where 90% of the trees in the random forest agree on a certain classification - it's possible that gates such as this may have fundamentally different characteristics than gates where the RF model is more evenly split on a class. It is then natural to expect that training a model specifically on gates of the second type may result in improved classification accuracy. Configuring a multi-pass model involves the specification of the number of models one wishes to use in a composite, as well as a range of probabilities to move on to the next pass. More is explained in the following. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a 2-pass model. Grid search testing on the validation dataset has shown that this number of passes best leverages the desire for performance with the retention of meteorological data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_models = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll define which gates are passed on to successive scans. \n",
    "\n",
    "\n",
    "`pass_1_probs = (.1,.9)`\n",
    "\n",
    "\n",
    "This means that gates where between 10-90% of the trees agree (inclusive) will be passed on to the second pass. \n",
    "Gates that <10% of the trees classify as meteorological will be assigned a label of non-meteorological and \n",
    "gates that >90% of trees classify as meteorological will be assigned a label of meteorological. This can be done for more passes, but we're just doing 2 as a minimal example.\n",
    "\n",
    "Met probabilities for the final pass of any composite model are interpreted somewhat differently. The maximum of the two probabilites will be taken, and gates where >= max percent of the trees classify a gate as meteorological will be assigned a label of meteorological/MD, with all other gates being assigned a label of non-meteorological/NMD. For example, if one were to set \n",
    "\n",
    "`final_met_prob = (.1,.9)`\n",
    "\n",
    "gates where >=90% of trees agree on a classification of meteorological would be assigned a label of meteorological/MD, with all other gates being assigned a label of non-meteorological/NMD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Tuple{Float64, Float64}}:\n",
       " (0.1, 0.9)\n",
       " (0.1, 0.9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "initial_met_prob = (.1, .9) \n",
    "final_met_prob = (.1,.9)\n",
    "\n",
    "###Combine into vector for model configuration object \n",
    "###It's important to note that len(met_probs) is enforced to be equal to num_models \n",
    "met_probs = [initial_met_prob, final_met_prob]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important feature of Ronin is its implementation of spatial features. These calculations take into account not only the gate of interest, but the gates surrounding it as well. The concept can be loosely equated to convolutions in a neural network. As such, it's important to specify weights for each surrounding observation/gate. Ronin provides a series of default weight matrixes that can be used to do so. More detail follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Vector{Matrix{Union{Missing, Float64}}}}:\n",
       " [[1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0]]\n",
       " [[1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###The following are default windows specified in RoninConstants.jl \n",
    "###Standard 7x7 window \n",
    "sw = Ronin.standard_window \n",
    "###7x7 window with only nonzero weights in azimuth dimension \n",
    "aw = Ronin.azi_window\n",
    "###7x7 window with only nonzero weights in range dimension \n",
    "rw = Ronin.range_window \n",
    "###Placeholder window for tasks that do not require spatial context \n",
    "pw = Ronin.placeholder_window \n",
    "\n",
    "###Specify a weight matrix for each individual task in the configuration file \n",
    "weight_vec = [pw, pw, pw, sw, sw, sw, aw, rw, pw, pw, pw, pw, pw]\n",
    "###Specify a weight vector for each model pass \n",
    "###len(weight_vector) is enforced to be equal to num_models (should have a set of weights for each pass) \n",
    "task_weights = [weight_vec, weight_vec] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{String}:\n",
       " \"PASS_1_MASK\"\n",
       " \"PASS_2_MASK\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "base_name = \"raw_model\"\n",
    "base_name_features = \"output_features\" \n",
    "###List of paths to output trained models to. Enforced to be same size as num_models \n",
    "model_output_paths = [base_name * \"_$(i-1).jld2\" for i in 1:num_models ]\n",
    "###List of paths to output calculated features to. Enforced to be same size as num_models \n",
    "feature_output_paths = [base_name_features * \"_$(i-1).h5\" for i in 1:num_models]\n",
    "\n",
    "\n",
    "###Options are \"balanced\" or \"\". If \"balanced\", the decision trees will be trained \n",
    "###on a weighted version of the existing classes in order to combat class imbalance \n",
    "class_weights = \"balanced\"\n",
    "\n",
    "###Name of variable in cfradials that has already had interactive QC applied \n",
    "QC_var = \"VG\"\n",
    "\n",
    "###Name of a variable in cfradials that will be used to mask what gates are predicted upon.\n",
    "###Missing values in this variable mean that gates will be removed - there is considered to be no data there\n",
    "###Generlly useful to have this be a raw variable \n",
    "remove_var = \"VV\"\n",
    "\n",
    "###Name of a variable in input cfradials that has not had postprocessing applied. \n",
    "###This variable is used to determine where MISSING gates exist in the scan \n",
    "remove_var = \"VEL\"\n",
    "\n",
    "###Whether or not the input features for the model have already been calculated \n",
    "file_preprocessed = [false, false]\n",
    "\n",
    "###Where to write out the masks to in cfradial file. \n",
    "mask_names = [\"PASS_1_MASK\", \"PASS_2_MASK\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig(2, [\"raw_model_0.jld2\", \"raw_model_1.jld2\"], [(0.1, 0.9), (0.1, 0.9)], [\"output_features_0.h5\", \"output_features_1.h5\"], \"/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING/\", \"nan\", Bool[0, 0], [\"./NOAA_all_params.txt\", \"./NOAA_all_params.txt\"], [\"\"], Vector[Matrix{Union{Missing, Float64}}[[1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0]], Matrix{Union{Missing, Float64}}[[1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0; … ; 1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0], [1.0 1.0 1.0; 1.0 1.0 1.0; 1.0 1.0 1.0]]], true, true, true, true, \"VG\", \"VEL\", -32000.0, false, true, false, [\"PASS_1_MASK\", \"PASS_2_MASK\"], [\"VEL\"], \"_QC\", \"balanced\", 21, 14, false)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Create model config object\n",
    "config = ModelConfig(num_models = num_models,model_output_paths =  model_output_paths,met_probs =  met_probs, \n",
    "                    feature_output_paths = feature_output_paths, input_path = input_path,task_mode=\"nan\",file_preprocessed = file_preprocessed,\n",
    "                     task_paths = task_paths, QC_var = QC_var, remove_var = remove_var, QC_mask = false, mask_names = mask_names,\n",
    "                     VARS_TO_QC = [\"VEL\"], class_weights = class_weights, HAS_INTERACTIVE_QC=true, task_weights = task_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Train a composite model!\n",
    "___\n",
    "Now that we have set up our model configuration, we simply invoke the `train_multi_model` function. This will likely take a long time, especially when one is training 2 or more models in a chain (1hr+). \n",
    "<b>Data will be written to the cfradial files during this process.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mCALCULATING FEATURES FOR PASS: 1\u001b[39m\n",
      "ERROR: POTENTIALLY INVALID FILE FORMAT FOR FILE: .tmp_hawkedit\n",
      "Processed /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING//cfrad.20220907_125500.003_to_20220907_125503.977_N42RF-TM_AIR.nc in 4.222163915634155 seconds\n",
      "Processed /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING//cfrad.20220907_125500.499_to_20220907_125504.479_N42RF-TS_AIR.nc in 0.7745208740234375 seconds\n",
      "Processed /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING//cfrad.20220907_125512.642_to_20220907_125516.616_N42RF-TM_AIR.nc in 0.8066399097442627 seconds\n",
      "Processed /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING//cfrad.20220907_125513.138_to_20220907_125517.117_N42RF-TS_AIR.nc in 0.7691159248352051 seconds\n",
      "Processed /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING//cfrad.20220907_125525.280_to_20220907_125529.254_N42RF-TM_AIR.nc in 0.8016760349273682 seconds\n",
      "Processed /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING//cfrad.20220907_125525.782_to_20220907_125529.755_N42RF-TS_AIR.nc in 0.8034348487854004 seconds\n",
      "Processed /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING//cfrad.20220907_125537.918_to_20220907_125541.892_N42RF-TM_AIR.nc in 0.7907140254974365 seconds\n",
      "Processed /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TRAINING//cfrad.20220907_125538.414_to_20220907_125542.394_N42RF-TS_AIR.nc in 0.7960898876190186 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mUNRECOVERABLE ERROR\u001b[39m\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] calculate_features(input_loc::String, argument_file::String, output_file::String, HAS_INTERACTIVE_QC::Bool; verbose::Bool, REMOVE_LOW_NCP::Bool, REMOVE_HIGH_PGG::Bool, QC_variable::String, remove_variable::String, replace_missing::Bool, write_out::Bool, QC_mask::Bool, mask_name::String, return_idxer::Bool, weight_matrixes::Vector{Matrix{Union{Missing, Float64}}})",
      "   @ Ronin ~/Documents/Grad_School/Research/Ronin/src/Ronin.jl:388",
      " [2] train_multi_model(config::ModelConfig)",
      "   @ Ronin ~/Documents/Grad_School/Research/Ronin/src/Ronin.jl:1358",
      " [3] top-level scope",
      "   @ In[10]:2"
     ]
    }
   ],
   "source": [
    "###Get rid of a bunch of annoying output \n",
    "%%capture \n",
    "\n",
    "\n",
    "###Train composite model! \n",
    "train_multi_model(config)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Verify the efficacy of the model on the testing dataset \n",
    "___\n",
    "We'll begin by setting up another `ModelConfig` struct, but this time substituting the path to the testing data for `input_path` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Tuple{Float64, Float64}}:\n",
       " (0.1, 0.9)\n",
       " (0.1, 0.95)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Switch input data to testing set \n",
    "config.input_path = TESTING_PATH\n",
    "###Let's also dial up the final met probs a bit to ensure the greatest amount of NMD removal possible \n",
    "config.met_probs = [inital_met_prob, (.1, .95)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, call the `composite_prediction` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Bool[0, 0, 0, 0, 0, 0, 1, 1, 1, 1  …  1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [0; 0; … ; 0; 0;;], [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  …  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%capture \n",
    "###I recommend setting `writ_features_out` to `true` so that predictions\n",
    "###can be retained for later usage \n",
    "predictions, verification, indexers = composite_prediction(config, write_features_out=true, feature_outfile=\"NEW_MODEL_PREDICTIONS_OUT.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's see how the model did using the `get_contingency` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>2×3 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\"></th><th style = \"text-align: left;\">True Meteorological</th><th style = \"text-align: left;\">True Non-Meteorological</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">Predicted Meteorological</td><td style = \"text-align: right;\">0.903</td><td style = \"text-align: right;\">0.035</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">Predicted Non-Meteorological</td><td style = \"text-align: right;\">0.097</td><td style = \"text-align: right;\">0.965</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t&  & True Meteorological & True Non-Meteorological\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Predicted Meteorological & 0.903 & 0.035 \\\\\n",
       "\t2 & Predicted Non-Meteorological & 0.097 & 0.965 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m2×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m                              \u001b[0m\u001b[1m True Meteorological \u001b[0m\u001b[1m True Non-Meteorologi\u001b[0m ⋯\n",
       "     │\u001b[90m String                       \u001b[0m\u001b[90m Float64             \u001b[0m\u001b[90m Float64             \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ Predicted Meteorological                    0.903                    0. ⋯\n",
       "   2 │ Predicted Non-Meteorological                0.097                    0.\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###If `normalize` is set to `true`, will return a contingency matrix where \n",
    "###Each column contains the predictions as a fraction of the total number of true values (each column will add to 1)\n",
    "get_contingency(predictions, Vector{Bool}(verification[:]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks pretty good! Lets now use it to actually apply quality control to the testing scans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: POTENTIALLY INVALID FILE FORMAT FOR FILE: .tmp_hawkedit\n",
      "\u001b[32mLOADING MODELS....\u001b[39m\n",
      "QC-ing /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125306.219_to_20220907_125310.193_N42RF-TM_AIR.ncINPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 4.16283392906189 seconds\n",
      "\n",
      "\u001b[32mREMOVED 6593 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 61644\n",
      "INPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 1.6243870258331299 seconds\n",
      "\n",
      "\u001b[32mREMOVED 4163 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 57481\n",
      "FINISHED QC-ing/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125306.219_to_20220907_125310.193_N42RF-TM_AIR.nc in 6.61QC-ing /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125306.750_to_20220907_125310.729_N42RF-TS_AIR.ncINPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 0.7043540477752686 seconds\n",
      "\n",
      "\u001b[32mREMOVED 7244 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 63667\n",
      "INPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 1.2304890155792236 seconds\n",
      "\n",
      "\u001b[32mREMOVED 3439 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 60228\n",
      "FINISHED QC-ing/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125306.750_to_20220907_125310.729_N42RF-TS_AIR.nc in 1.96QC-ing /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125318.857_to_20220907_125322.837_N42RF-TM_AIR.ncINPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 0.675724983215332 seconds\n",
      "\n",
      "\u001b[32mREMOVED 6561 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 61878\n",
      "INPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 1.0764169692993164 seconds\n",
      "\n",
      "\u001b[32mREMOVED 4245 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 57633\n",
      "FINISHED QC-ing/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125318.857_to_20220907_125322.837_N42RF-TM_AIR.nc in 1.8QC-ing /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125319.388_to_20220907_125323.368_N42RF-TS_AIR.ncINPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 0.6715691089630127 seconds\n",
      "\n",
      "\u001b[32mREMOVED 7008 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 64072\n",
      "INPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 1.1389129161834717 seconds\n",
      "\n",
      "\u001b[32mREMOVED 3287 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 60785\n",
      "FINISHED QC-ing/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125319.388_to_20220907_125323.368_N42RF-TS_AIR.nc in 1.84QC-ing /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125331.495_to_20220907_125335.475_N42RF-TM_AIR.ncINPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 0.674346923828125 seconds\n",
      "\n",
      "\u001b[32mREMOVED 6471 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 62195\n",
      "INPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 1.0935349464416504 seconds\n",
      "\n",
      "\u001b[32mREMOVED 3791 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 58404\n",
      "FINISHED QC-ing/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125331.495_to_20220907_125335.475_N42RF-TM_AIR.nc in 1.8QC-ing /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125332.026_to_20220907_125336.006_N42RF-TS_AIR.ncINPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 0.8800749778747559 seconds\n",
      "\n",
      "\u001b[32mREMOVED 7061 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 64821\n",
      "INPUT_SET NCDatasets.NCDataset{Nothing, Missing}, VAR: StringAlready exists... overwriting\n",
      "\n",
      "Completed in 1.2443609237670898 seconds\n",
      "\n",
      "\u001b[32mREMOVED 3566 PRESUMED NON-METEORLOGICAL DATAPOINTS\u001b[39m\n",
      "FINAL COUNT OF DATAPOINTS IN VEL: 61255\n",
      "FINISHED QC-ing/Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125332.026_to_20220907_125336.006_N42RF-TS_AIR.nc in 2.15QC-ing /Users/ischluesche/Documents/Grad_School/Research/Ronin/NOAA/TESTING//cfrad.20220907_125344.168_to_20220907_125348.142_N42RF-TM_AIR.nc"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "NetCDF error: \u001b[31mNetCDF: HDF error\u001b[39m (NetCDF error code: -101)",
     "output_type": "error",
     "traceback": [
      "NetCDF error: \u001b[31mNetCDF: HDF error\u001b[39m (NetCDF error code: -101)",
      "",
      "Stacktrace:",
      " [1] check",
      "   @ ~/.julia/packages/NCDatasets/ivzVX/src/errorhandling.jl:25 [inlined]",
      " [2] nc_close(ncid::Int32)",
      "   @ NCDatasets ~/.julia/packages/NCDatasets/ivzVX/src/netcdf_c.jl:1217",
      " [3] close(ds::NCDatasets.NCDataset{Nothing, Missing})",
      "   @ NCDatasets ~/.julia/packages/NCDatasets/ivzVX/src/dataset.jl:299",
      " [4] NCDatasets.NCDataset(::Ronin.var\"#122#123\"{Bool, String, ModelConfig, Vector{Any}, Int64}, ::String, ::Vararg{String}; kwargs::@Kwargs{})",
      "   @ NCDatasets ~/.julia/packages/NCDatasets/ivzVX/src/dataset.jl:254",
      " [5] NCDataset",
      "   @ ~/.julia/packages/NCDatasets/ivzVX/src/dataset.jl:248 [inlined]",
      " [6] QC_scan(config::ModelConfig; output_probs::Bool, prob_name::String)",
      "   @ Ronin ~/Documents/Grad_School/Research/Ronin/src/Ronin.jl:1906",
      " [7] top-level scope",
      "   @ In[6]:1"
     ]
    }
   ],
   "source": [
    "QC_scan(test_config, output_probs=true, prob_name=\"MET_GATE_PROB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_config.QC_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
