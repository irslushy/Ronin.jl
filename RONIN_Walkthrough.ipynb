{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RONIN Walkthrough \n",
    "___\n",
    "\n",
    "This notebook contains a brief introduction to training and evaluating a random forest radar quality control algorithm using Julia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Begin by loading dependencies \n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate() \n",
    "##Make sure Julia can see our module \n",
    "push!(LOAD_PATH, \"./src/\")\n",
    "\n",
    "###Load key functionality \n",
    "###This will take a while the first time you do it \n",
    "using Ronin "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Splitting data into training and testing sets\n",
    "___\n",
    "We'll begin by partitioning our data into scans that will be used for training the model (training set) and scans that will be used to evaluate model performance (testing set). It's important to keep these separate. \n",
    "<h2><span style=\"color:Red\">WARNING: This function will begin by DELETING the training and testing directories to clean them</span></h2>\n",
    "It then softlinks the divded files to their respective directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Make sure to use absolute paths here \n",
    "##These are EXAMPLES, make sure to edit for your own directory setup\n",
    "CASE_PATHS= [\"./CFRADIALS/CASES/BAMEX\", \n",
    "             \"./CFRADIALS/CASES/HAGUPIT\", \n",
    "             \"./CFRADIALS/CASES/RITA\", \n",
    "             \"./CFRADIALS/CASES/VORTEX\"]\n",
    "\n",
    "TRAINING_PATH = \"./CFRADIALS/CASES/TRAINING\"\n",
    "TESTING_PATH  = \"./CFRADIALS/CASES/TESTING\"\n",
    "\n",
    "split_training_testing!([CASE_PATHS], TRAINING_PATH, TESTING_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Configure model\n",
    "___\n",
    "We'll now set up a configuartion object for use in our model. This structure contains \n",
    "key information and settings such as the number of models to use, the decision thresholds for each model, and locations to output data to. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, the first step in the process is calculating a set of input features containing information about each gate in the training radar sweeps.\n",
    "`task_paths` specifies the location of the file containing the information about what features the user wishes to calculate. It should be the same length as the number of models in the chain (more below). \n",
    "`input_path` is the path to the file \n",
    "or directory where the sweeps are located. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_paths = [\"./standard_model/final_model_tasks_1.txt\", \"./standard_model/final_model_tasks_2.txt\"]\n",
    "input_path = TRAINING_PATH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ronin can also create a \"multi-pass\" model, where a model is trained on the full dataset, and successive models are trained on subsets of these data. The motivation for this setup is to leverage the probablistic information provided by the random forest approach. Consider a gate where 90% of the trees in the random forest agree on a certain classification - it's possible that gates such as this may have fundamentally different characteristics than gates where the RF model is more evenly split on a class. It is then natural to expect that training a model specifically on gates of the second type may result in improved classification accuracy. Configuring a multi-pass model involves the specification of the number of models one wishes to use in a composite, as well as a range of probabilities to move on to the next pass. More is explained in the following. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a 2-pass model. Grid search testing on the validation dataset has shown that this number of passes best leverages the desire for performance with the retention of meteorological data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll define which gates are passed on to successive scans. \n",
    "\n",
    "\n",
    "`pass_1_probs = (.1,.9)`\n",
    "\n",
    "\n",
    "This means that gates where between 10-90% of the trees agree (inclusive) will be passed on to the second pass. \n",
    "Gates that <10% of the trees classify as meteorological will be assigned a label of non-meteorological and \n",
    "gates that >90% of trees classify as meteorological will be assigned a label of meteorological. This can be done for more passes, but we're just doing 2 as a minimal example.\n",
    "\n",
    "Met probabilities for the final pass of any composite model are interpreted somewhat differently. The maximum of the two probabilites will be taken, and gates where >= max percent of the trees classify a gate as meteorological will be assigned a label of meteorological/MD, with all other gates being assigned a label of non-meteorological/NMD. For example, if one were to set \n",
    "\n",
    "`final_met_prob = (.1,.9)`\n",
    "\n",
    "gates where >=90% of trees agree on a classification of meteorological would be assigned a label of meteorological/MD, with all other gates being assigned a label of non-meteorological/NMD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_met_prob = (.1f0, .9f0)\n",
    "final_met_prob = (.1f0, .9f0)\n",
    "\n",
    "###Combine into vector for model configuration object \n",
    "###It's important to note that len(met_probs) is enforced to be equal to num_models \n",
    "met_probs = [initial_met_prob, final_met_prob]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important feature of Ronin is its implementation of spatial features. These calculations take into account not only the gate of interest, but the gates surrounding it as well. The concept can be loosely equated to convolutions in a neural network. As such, it's important to specify weights for each surrounding observation/gate. Ronin provides a series of default weight matrixes that can be used to do so. More detail follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###The following are default windows specified in RoninConstants.jl \n",
    "###Standard 7x7 window \n",
    "sw = Ronin.standard_window \n",
    "###7x7 window with only nonzero weights in azimuth dimension \n",
    "aw = Ronin.azi_window\n",
    "###7x7 window with only nonzero weights in range dimension \n",
    "rw = Ronin.range_window \n",
    "###Placeholder window for tasks that do not require spatial context \n",
    "pw = Ronin.placeholder_window \n",
    "\n",
    "###Specify a weight matrix for each individual task in the configuration file \n",
    "###For this model, we are being aggressive and there are a lot of tasks in the task file, \n",
    "###so add a lot of different windows in range and azimuth. \n",
    "weight_vec_1 = [rw, aw, sw, rw, aw, sw, rw, aw, sw, rw, aw, sw, pw, pw, pw, pw, pw]\n",
    "weight_vec_2 = [pw, pw, sw, sw, sw, sw, sw, pw, pw, pw, pw, pw]\n",
    "###Specify a weight vector for each model pass \n",
    "###len(weight_vector) is enforced to be equal to num_models (should have a set of weights for each pass) \n",
    "task_weights = [weight_vec_1, weight_vec_2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = \"raw_model\"\n",
    "base_name_features = \"output_features\" \n",
    "###List of paths to output trained models to. Enforced to be same size as num_models \n",
    "model_output_paths = [base_name * \"_$(i-1).jld2\" for i in 1:num_models ]\n",
    "###List of paths to output calculated features to. Enforced to be same size as num_models \n",
    "feature_output_paths = [base_name_features * \"_$(i-1).h5\" for i in 1:num_models]\n",
    "\n",
    "\n",
    "###Options are \"balanced\" or \"\". If \"balanced\", the decision trees will be trained \n",
    "###on a weighted version of the existing classes in order to combat class imbalance \n",
    "class_weights = \"balanced\"\n",
    "\n",
    "###Name of variable in cfradials that has already had interactive QC applied \n",
    "QC_var = \"VG\"\n",
    "\n",
    "###Name of a variable in cfradials that will be used to mask what gates are predicted upon.\n",
    "###Missing values in this variable mean that gates will be removed - there is considered to be no data there\n",
    "###Generlly useful to have this be a raw variable \n",
    "remove_var = \"VV\"\n",
    "\n",
    "###Name of a variable in input cfradials that has not had postprocessing applied. \n",
    "###This variable is used to determine where MISSING gates exist in the scan \n",
    "remove_var = \"VEL\"\n",
    "\n",
    "###Whether or not the input features for the model have already been calculated \n",
    "file_preprocessed = [false, false]\n",
    "\n",
    "###Where to write out the masks to in cfradial file. \n",
    "mask_names = [\"PASS_1_MASK\", \"PASS_2_MASK\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create model config object\n",
    "config = ModelConfig(num_models = num_models,model_output_paths =  model_output_paths,met_probs =  met_probs, \n",
    "                    feature_output_paths = feature_output_paths, input_path = TRAINING_PATH,task_mode=\"nan\",file_preprocessed = file_preprocessed,\n",
    "                     task_paths = task_paths, QC_var = QC_var, remove_var = remove_var, QC_mask = false, mask_names = mask_names,\n",
    "                     VARS_TO_QC = [\"VEL\"], class_weights = class_weights, HAS_INTERACTIVE_QC=true, task_weights = task_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Train a composite model!\n",
    "___\n",
    "Now that we have set up our model configuration, we simply invoke the `train_multi_model` function. This will likely take a long time, especially when one is training 2 or more models in a chain (1hr+). \n",
    "<b>Data will be written to the cfradial files during this process.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Train composite model! \n",
    "train_multi_model(config)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Verify the efficacy of the model on the testing dataset \n",
    "___\n",
    "We'll begin by setting up another `ModelConfig` struct, but this time substituting the path to the testing data for `input_path` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Switch input data to testing set \n",
    "config.input_path = TESTING_PATH\n",
    "###Let's also dial up the final met probs a bit to ensure the greatest amount of NMD removal possible \n",
    "config.met_probs = [(.1f0, .9f0), (.1f0, .95f0)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, call the `composite_prediction` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###I recommend setting `write_predictions_out` to `true` so that predictions\n",
    "###can be retained for later usage \n",
    "predictions, verification, indexers = composite_prediction(config; write_predictions_out=true, prediction_outfile=\"NEW_MODEL_PREDICTIONS_OUT.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's see how the model did using the `get_contingency` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###If `normalize` is set to `true`, will return a contingency matrix where \n",
    "###Each column contains the predictions as a fraction of the total number of true values (each column will add to 1)\n",
    "get_contingency(predictions, Vector{Bool}(verification[:]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks pretty good! Lets now use it to actually apply quality control to the testing scans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QC_scan(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
